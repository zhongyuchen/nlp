{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第11章 分析句子结构\n",
    "\n",
    "## 本章目标\n",
    "* 如何使用形式化语法来描述句子集合的结构？\n",
    "* 如何使用句法树来表示句子结构？\n",
    "* 语法分析器如何分析一个句子并自动构建语法树？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内容\n",
    "* 结构分析的歧义\n",
    "* 文法的作用\n",
    "* 上下文无关文法\n",
    "* 上下文无关文法分析\n",
    "* 依存关系和依存文法\n",
    "* 文法开发\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结构分析的歧义\n",
    "由词组成词组乃至句子时，由于其组成的词或词组间可能存在不同的语法或语义关系而出现的（潜在）歧义现象\n",
    "* “VP＋的＋是＋NP”型歧义结构 \n",
    "  * “反对│的│是│少数人” \n",
    "* “N1＋N2＋N3”型歧义结构 \n",
    "  * “北欧│语言│研究会 ”\n",
    "* “ADJ.＋N1＋N2”型歧义结构\n",
    "  * “小│学生│词典” \n",
    "* “VP＋N1＋的＋N2”型歧义结构 \n",
    "  * “咬死了│猎人│的│狗 ”\n",
    "* “VP＋ADJ.＋的＋N”型歧义结构 \n",
    "  * “喜欢│干净│的│小孩 ”\n",
    "* “V＋N1＋N2”型歧义结构 \n",
    "  * “赠│意大利│图书”\n",
    "* “数量结构＋NP1＋的＋NP2”型歧义结构\n",
    "  * “三个│学校│的│实验员”\n",
    "* 英语的例子\n",
    "  * Fighting animals could be dangerous. \n",
    "  * Visiting relatives can be tiresome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "花园幽径句\n",
    "* 我是县长派来的\n",
    "* 我是县长\n",
    "* Put the frog on the napkin in the box\n",
    "* Put the frog on the napkin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "歧义和树结构\n",
    "\n",
    "While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "    \"\"\")\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/ch08-tree-1.png)\n",
    "\n",
    "![title](img/ch08-tree-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 上下文无关文法\n",
    "\n",
    "第一条产生式的左端是文法的开始符号，通常是S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文法的作用\n",
    "“产生式文法”形式化框架\n",
    "* “语言”被认为是所有合乎文法的句子的集合\n",
    "* 文法是一组形式化符号，可用于“产生”这个集合的成员\n",
    "\n",
    "成分结构\n",
    "* 在符合语法规则的句子中，词序列可以被更短的序列替代，而不会导致句子不符合语法规则\n",
    "* 例如： The little bear saw the fine fat trout in the brook.  He saw the fine fat trout in the brook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词序列的替代\n",
    "\n",
    "从最上面一排开始，用单个的词（如：it）替换词序列（如：the brook）\n",
    "\n",
    "文法分类: 名词短语（NP），动词短语（VP），介词短语（PP）\n",
    "\n",
    "![title](img/ic_diagram_labeled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 短语结构树\n",
    "\n",
    "树的每个节点（包括词）被称为一个成分(constituent)\n",
    "\n",
    "* 如S 的直接成分是NP 和VP\n",
    "\n",
    "![title](img/ch08-tree-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上下文无关文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归下降分析器演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析结果示例\n",
    "![title](img/ch08-tree-4.png)\n",
    "\n",
    "![title](img/ch08-tree-5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 句法结构中的递归\n",
    "\n",
    "一个文法被认为是递归的，如果文法类型出现在产生式左侧也出现在右侧\n",
    "\n",
    "直接递归：Nom -> Adj Nom\n",
    "\n",
    "间接递归：S -> NP VP 与VP -> V S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "  S  -> NP VP\n",
    "  NP -> Det Nom | PropN\n",
    "  Nom -> Adj Nom | N\n",
    "  VP -> V Adj | V NP | V S | V NP PP\n",
    "  PP -> P NP\n",
    "  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "  Det -> 'the' | 'a'\n",
    "  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
    "  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "  P -> 'on'\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析结果示例\n",
    "![title](img/ch08-tree-6.png)\n",
    "\n",
    "\n",
    "![title](img/ch08-tree-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上下文无关文法分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析器根据文法产生式处理输入的句子，并生成一个或多个符合文法的成分结构\n",
    "    \n",
    "    文法是良构的声明规范，也是字符串\n",
    "    \n",
    "    分析器是文法的解释程序\n",
    "\n",
    "#### 分析算法\n",
    "\n",
    "#### 递归下降分析：自顶向下\n",
    "\n",
    "递归下降分析器实现\n",
    "\n",
    "缺点：1）左递归产生式，如：NP -> NP PP，会进入死循环\n",
    "\n",
    "2）分析器浪费了很多时间处理不匹配输入句子的词和结构\n",
    "\n",
    "3）回溯过程中会丢弃分析过的成分，它们在将来可能需要重建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/rdparser1-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "递归下降分析器实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * S ]\n",
      "  E [ * NP VP ]\n",
      "  E [ * 'John' VP ]\n",
      "  E [ * 'Mary' VP ]\n",
      "  M [ 'Mary' * VP ]\n",
      "  E [ 'Mary' * V NP ]\n",
      "  E [ 'Mary' * 'saw' NP ]\n",
      "  M [ 'Mary' 'saw' * NP ]\n",
      "  E [ 'Mary' 'saw' * 'John' ]\n",
      "  E [ 'Mary' 'saw' * 'Mary' ]\n",
      "  E [ 'Mary' 'saw' * 'Bob' ]\n",
      "  E [ 'Mary' 'saw' * Det N ]\n",
      "  E [ 'Mary' 'saw' * 'a' N ]\n",
      "  M [ 'Mary' 'saw' 'a' * N ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' ]\n",
      "  + [ 'Mary' 'saw' 'a' 'dog' ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' ]\n",
      "  E [ 'Mary' 'saw' * 'an' N ]\n",
      "  E [ 'Mary' 'saw' * 'the' N ]\n",
      "  E [ 'Mary' 'saw' * 'my' N ]\n",
      "  E [ 'Mary' 'saw' * Det N PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP ]\n",
      "  E [ 'Mary' * 'ate' NP ]\n",
      "  E [ 'Mary' * 'walked' NP ]\n",
      "  E [ 'Mary' * V NP PP ]\n",
      "  E [ 'Mary' * 'saw' NP PP ]\n",
      "  M [ 'Mary' 'saw' * NP PP ]\n",
      "  E [ 'Mary' 'saw' * 'John' PP ]\n",
      "  E [ 'Mary' 'saw' * 'Mary' PP ]\n",
      "  E [ 'Mary' 'saw' * 'Bob' PP ]\n",
      "  E [ 'Mary' 'saw' * Det N PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP ]\n",
      "  E [ 'Mary' 'saw' * Det N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP PP ]\n",
      "  E [ 'Mary' * 'ate' NP PP ]\n",
      "  E [ 'Mary' * 'walked' NP PP ]\n",
      "  E [ * 'Bob' VP ]\n",
      "  E [ * Det N VP ]\n",
      "  E [ * 'a' N VP ]\n",
      "  E [ * 'an' N VP ]\n",
      "  E [ * 'the' N VP ]\n",
      "  E [ * 'my' N VP ]\n",
      "  E [ * Det N PP VP ]\n",
      "  E [ * 'a' N PP VP ]\n",
      "  E [ * 'an' N PP VP ]\n",
      "  E [ * 'the' N PP VP ]\n",
      "  E [ * 'my' N PP VP ]\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1,trace=2)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "递归下降分析器的缺点\n",
    "* 左递归产生式，如：NP -> NP PP，会进入死循环\n",
    "* 分析器浪费了很多时间处理不匹配输入句子的词和结构\n",
    "* 回溯过程中会丢弃分析过的成分，它们在将来可能需要重建\n",
    " * 例如：从VP -> V NP 上回溯将放弃为NP 创建的子树。如果分析器之后处理VP -> V NP PP，那* 么NP 子树必须重新创建\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移进-归约分析\n",
    "* 递归下降分析是一种自顶向下分析：在检查输入之前先使用文法预测输入将是什么！\n",
    "* 移进-归约分析是一种自底向上分析：由于输入对分析器一直是可用的，从一开始就考虑输入的句子\n",
    "* 移进-归约分析器尝试找到对应文法生产式右侧的词和短语的序列，用左侧符号的替换它们，直到整个句子归约为一个S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 移进-归约过程\n",
    "\n",
    "1）移位操作(shift): 将下一个输入词移入堆栈\n",
    "\n",
    "2）归约操作(reduce): 如果堆栈上的前n 项，匹配某个产生式的右侧的n 个项目，那么就把它们弹出栈，并把产生式左边的项目压入栈\n",
    "    \n",
    "    此操作只适用于堆栈的顶部\n",
    "    \n",
    "    此操作必须在后面的项目被压入栈之前做\n",
    "\n",
    "3）当所有的输入都使用过，堆栈中只剩余一个项目，也就是一棵分析树作为它的根的S 节点时，分析完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移进-归约分析器的六个阶段\n",
    "\n",
    "![title](img/srparser1-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移进-归约分析器实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * Mary saw a dog]\n",
      "  S [ 'Mary' * saw a dog]\n",
      "  R [ NP * saw a dog]\n",
      "  S [ NP 'saw' * a dog]\n",
      "  R [ NP V * a dog]\n",
      "  S [ NP V 'a' * dog]\n",
      "  R [ NP V Det * dog]\n",
      "  S [ NP V Det 'dog' * ]\n",
      "  R [ NP V Det N * ]\n",
      "  R [ NP V NP * ]\n",
      "  R [ NP VP * ]\n",
      "  R [ S * ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1,trace=2)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移进-归约分析器相比自顶向下分析器的优点：它们只建立与输入中的词对应的结构，且每个结构只建立一次\n",
    "* 例如：NP(Det(the), N(man))只建立和压入栈一次，不管以后VP -> V NP PP 归约或者NP -> NP PP归约会不会用到\n",
    "\n",
    "移进-归约分析器的冲突\n",
    "* 当有多种归约可能时选择哪个归约\n",
    "* 当移进和归约都可以时选择哪个动作\n",
    "* 通过改进执行策略解决冲突\n",
    "* 向前看：LR分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.app.srparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线图分析示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
    "    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1,nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1,nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % \\\n",
    "                        (start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst, tokens):\n",
    "    print('\\nWFST ' + ' '.join((\"%-4d\" % i) for i in range(1, len(wfst))))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d   \" % i, end=\" \")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" % (wfst[i][j] or '.'), end=\" \")\n",
    "        print()\n",
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.app.chartparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存关系和依存文法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 什么是依存关系和依存文法\n",
    "* NLTK如何表示依存关系\n",
    "* 如何确定中心词和从属词\n",
    "* 动词与配价\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存关系和依存文法\n",
    "依存文法集中关注词与其他词之间的关系\n",
    "\n",
    "依存关系是中心词与从属词之间的二元对称关系\n",
    "* 句子的中心词通常是动词，所有其他词要么依赖于中心词，要么依赖路径与它连通\n",
    "\n",
    "依存关系表示为带标签的有向图，其中节点是词语，弧表示依存关系，标签表示语法功能，箭头从中心词指向从属词\n",
    "\n",
    "![title](img/depgraph0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK表示依存关系\n",
    "\n",
    "只捕捉依存关系，不指定依存关系类型\n",
    "\n",
    "投影式的依存关系：没有交叉边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "... 'shot' -> 'I' | 'elephant' | 'in'\n",
    "... 'elephant' -> 'an' | 'in'\n",
    "... 'in' -> 'pajamas'\n",
    "... 'pajamas' -> 'my'\n",
    "... \"\"\")\n",
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理附着歧义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/ch08-tree-10.png)\n",
    "![title](img/ch08-tree-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何确定中心词和从属词\n",
    "* H 决定D的句法范畴；或者，D 的外部句法属性取决于H\n",
    "* H 定义D 的语义范畴\n",
    "* H 必须有而D 是可选的\n",
    "* H 选择D 并且决定它是必须有的还是可选的\n",
    "* D 的形态由H 决定（如agreement 或case government）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动词与配价\n",
    "\n",
    "a.\t\tThe squirrel was frightened.\n",
    "\n",
    "b.\t\tChatterer saw the bear.\n",
    "\n",
    "c.\t\tChatterer thought Buster was angry.\n",
    "\n",
    "d.\t\tJoe put the fish on the log.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不符合语法规则的词序列\n",
    "\n",
    "a. *The squirrel was Buster was angry.\n",
    "\n",
    "b. *Chatterer saw frightened.\n",
    "\n",
    "c. *Chatterer thought the bear.\n",
    "\n",
    "d. *Joe put on the log.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文法开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 树库(TreeBank)与文法\n",
    "\n",
    "corpus 模块定义了树库语料的阅读器，其中包含了宾州树库语料的10％样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用树库开发文法\n",
    "\n",
    "使用过滤器找出带补语的动词\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter(tree):\n",
    "    child_nodes = [child.label() for child in tree\n",
    "                   if isinstance(child, nltk.Tree)]\n",
    "    return  (tree.label() == 'VP') and ('S' in child_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "[subtree for tree in treebank.parsed_sents()\n",
    " for subtree in tree.subtrees(filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出具有固定的介词和名词的介词短语对，其中介词短语附着到VP 还是NP，由选择的动词决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "entries = nltk.corpus.ppattach.attachments('training')\n",
    "table = defaultdict(lambda: defaultdict(set))\n",
    "for entry in entries:\n",
    "    key = entry.noun1 + '-' + entry.prep + '-' + entry.noun2\n",
    "    table[key][entry.attachment].add(entry.verb)\n",
    "for key in sorted(table):\n",
    "    if len(table[key]) > 1:\n",
    "        print(key, 'N:', sorted(table[key]['N']), 'V:', sorted(table[key]['V']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 歧义的害处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "... S -> NP V NP\n",
    "... NP -> NP Sbar\n",
    "... Sbar -> NP V\n",
    "... NP -> 'fish'\n",
    "... V -> 'fish'\n",
    "... \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [\"fish\"] * 5\n",
    "cp = nltk.ChartParser(grammar)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着句子长度增加到（3，5，7，...），我们得到的分析树的数量是：1; 2; 5; 14; 42; 132; 429; 1,430; 4,862; 16,796; 58,786; 208,012; …."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加权文法\n",
    "\n",
    "处理歧义是开发分析器的主要挑战，加权文法和概率分析算法为这些问题提供了一个有效的解决方案\n",
    "\n",
    "以动词give为例，它需要直接宾语和间接宾语，这些补语可以按任何顺序出现\n",
    "\n",
    "example:宾州树库样本中give和gave的用法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def give(t):\n",
    "    return t.label() == 'VP' and len(t) > 2 and t[1].label() == 'NP'\\\n",
    "           and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP')\\\n",
    "           and ('give' in t[0].leaves() or 'gave' in t[0].leaves())\n",
    "def sent(t):\n",
    "    return ' '.join(token for token in t.leaves() if token[0] not in '*-0')\n",
    "def print_node(t, width):\n",
    "        output = \"%s %s: %s / %s: %s\" %\\\n",
    "            (sent(t[0]), t[1].label(), sent(t[1]), t[2].label(), sent(t[2]))\n",
    "        if len(output) > width:\n",
    "            output = output[:width] + \"...\"\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    for t in tree.subtrees(give):\n",
    "        print_node(t, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 概率上下文无关文法\n",
    "\n",
    "概率上下文无关文法是一种上下文无关文法，每一个产生式关联一个概率\n",
    "\n",
    "它会产生与相应的上下文无关文法相同的文本分析树，并给每个分析树分配一个概率\n",
    "\n",
    "所产生的分析树的概率仅仅是它用到的产生式的概率的乘积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S    -> NP VP              [1.0]\n",
    "    VP   -> TV NP              [0.4]\n",
    "    VP   -> IV                 [0.3]\n",
    "    VP   -> DatV NP NP         [0.3]\n",
    "    TV   -> 'saw'              [1.0]\n",
    "    IV   -> 'ate'              [1.0]\n",
    "    DatV -> 'gave'             [1.0]\n",
    "    NP   -> 'telescopes'       [0.8]\n",
    "    NP   -> 'Jack'             [0.2]\n",
    "    \"\"\")\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viterbi_parser = nltk.ViterbiParser(grammar)\n",
    "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
